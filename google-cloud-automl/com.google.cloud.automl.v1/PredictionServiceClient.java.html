<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../../jacoco-resources/report.gif" type="image/gif"/><title>PredictionServiceClient.java</title><link rel="stylesheet" href="../../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../../index.html" class="el_report">CoverageAggregator</a> &gt; <a href="../index.html" class="el_bundle">google-cloud-automl</a> &gt; <a href="index.source.html" class="el_package">com.google.cloud.automl.v1</a> &gt; <span class="el_source">PredictionServiceClient.java</span></div><h1>PredictionServiceClient.java</h1><pre class="source lang-java linenums">/*
 * Copyright 2022 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.google.cloud.automl.v1;

import com.google.api.gax.core.BackgroundResource;
import com.google.api.gax.longrunning.OperationFuture;
import com.google.api.gax.rpc.OperationCallable;
import com.google.api.gax.rpc.UnaryCallable;
import com.google.cloud.automl.v1.stub.PredictionServiceStub;
import com.google.cloud.automl.v1.stub.PredictionServiceStubSettings;
import com.google.longrunning.Operation;
import com.google.longrunning.OperationsClient;
import java.io.IOException;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import javax.annotation.Generated;

// AUTO-GENERATED DOCUMENTATION AND CLASS.
/**
 * Service Description: AutoML Prediction API.
 *
 * &lt;p&gt;On any input that is documented to expect a string parameter in snake_case or dash-case,
 * either of those cases is accepted.
 *
 * &lt;p&gt;This class provides the ability to make remote calls to the backing service through method
 * calls that map to API methods. Sample code to get started:
 *
 * &lt;pre&gt;{@code
 * // This snippet has been automatically generated for illustrative purposes only.
 * // It may require modifications to work in your environment.
 * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
 *   ModelName name = ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;);
 *   ExamplePayload payload = ExamplePayload.newBuilder().build();
 *   Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
 *   PredictResponse response = predictionServiceClient.predict(name, payload, params);
 * }
 * }&lt;/pre&gt;
 *
 * &lt;p&gt;Note: close() needs to be called on the PredictionServiceClient object to clean up resources
 * such as threads. In the example above, try-with-resources is used, which automatically calls
 * close().
 *
 * &lt;p&gt;The surface of this class includes several types of Java methods for each of the API's
 * methods:
 *
 * &lt;ol&gt;
 *   &lt;li&gt;A &quot;flattened&quot; method. With this type of method, the fields of the request type have been
 *       converted into function parameters. It may be the case that not all fields are available as
 *       parameters, and not every API method will have a flattened method entry point.
 *   &lt;li&gt;A &quot;request object&quot; method. This type of method only takes one parameter, a request object,
 *       which must be constructed before the call. Not every API method will have a request object
 *       method.
 *   &lt;li&gt;A &quot;callable&quot; method. This type of method takes no parameters and returns an immutable API
 *       callable object, which can be used to initiate calls to the service.
 * &lt;/ol&gt;
 *
 * &lt;p&gt;See the individual methods for example code.
 *
 * &lt;p&gt;Many parameters require resource names to be formatted in a particular way. To assist with
 * these names, this class includes a format method for each type of name, and additionally a parse
 * method to extract the individual identifiers contained within names that are returned.
 *
 * &lt;p&gt;This class can be customized by passing in a custom instance of PredictionServiceSettings to
 * create(). For example:
 *
 * &lt;p&gt;To customize credentials:
 *
 * &lt;pre&gt;{@code
 * // This snippet has been automatically generated for illustrative purposes only.
 * // It may require modifications to work in your environment.
 * PredictionServiceSettings predictionServiceSettings =
 *     PredictionServiceSettings.newBuilder()
 *         .setCredentialsProvider(FixedCredentialsProvider.create(myCredentials))
 *         .build();
 * PredictionServiceClient predictionServiceClient =
 *     PredictionServiceClient.create(predictionServiceSettings);
 * }&lt;/pre&gt;
 *
 * &lt;p&gt;To customize the endpoint:
 *
 * &lt;pre&gt;{@code
 * // This snippet has been automatically generated for illustrative purposes only.
 * // It may require modifications to work in your environment.
 * PredictionServiceSettings predictionServiceSettings =
 *     PredictionServiceSettings.newBuilder().setEndpoint(myEndpoint).build();
 * PredictionServiceClient predictionServiceClient =
 *     PredictionServiceClient.create(predictionServiceSettings);
 * }&lt;/pre&gt;
 *
 * &lt;p&gt;Please refer to the GitHub repository's samples for more quickstart code snippets.
 */
@Generated(&quot;by gapic-generator-java&quot;)
public class PredictionServiceClient implements BackgroundResource {
  private final PredictionServiceSettings settings;
  private final PredictionServiceStub stub;
  private final OperationsClient operationsClient;

  /** Constructs an instance of PredictionServiceClient with default settings. */
  public static final PredictionServiceClient create() throws IOException {
<span class="nc" id="L114">    return create(PredictionServiceSettings.newBuilder().build());</span>
  }

  /**
   * Constructs an instance of PredictionServiceClient, using the given settings. The channels are
   * created based on the settings passed in, or defaults for any settings that are not set.
   */
  public static final PredictionServiceClient create(PredictionServiceSettings settings)
      throws IOException {
<span class="fc" id="L123">    return new PredictionServiceClient(settings);</span>
  }

  /**
   * Constructs an instance of PredictionServiceClient, using the given stub for making calls. This
   * is for advanced usage - prefer using create(PredictionServiceSettings).
   */
  public static final PredictionServiceClient create(PredictionServiceStub stub) {
<span class="nc" id="L131">    return new PredictionServiceClient(stub);</span>
  }

  /**
   * Constructs an instance of PredictionServiceClient, using the given settings. This is protected
   * so that it is easy to make a subclass, but otherwise, the static factory methods should be
   * preferred.
   */
<span class="fc" id="L139">  protected PredictionServiceClient(PredictionServiceSettings settings) throws IOException {</span>
<span class="fc" id="L140">    this.settings = settings;</span>
<span class="fc" id="L141">    this.stub = ((PredictionServiceStubSettings) settings.getStubSettings()).createStub();</span>
<span class="fc" id="L142">    this.operationsClient = OperationsClient.create(this.stub.getOperationsStub());</span>
<span class="fc" id="L143">  }</span>

<span class="nc" id="L145">  protected PredictionServiceClient(PredictionServiceStub stub) {</span>
<span class="nc" id="L146">    this.settings = null;</span>
<span class="nc" id="L147">    this.stub = stub;</span>
<span class="nc" id="L148">    this.operationsClient = OperationsClient.create(this.stub.getOperationsStub());</span>
<span class="nc" id="L149">  }</span>

  public final PredictionServiceSettings getSettings() {
<span class="nc" id="L152">    return settings;</span>
  }

  public PredictionServiceStub getStub() {
<span class="nc" id="L156">    return stub;</span>
  }

  /**
   * Returns the OperationsClient that can be used to query the status of a long-running operation
   * returned by another API method call.
   */
  public final OperationsClient getOperationsClient() {
<span class="nc" id="L164">    return operationsClient;</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform an online prediction. The prediction result is directly returned in the response.
   * Available for following ML scenarios, and their expected request payloads:
   *
   * &lt;p&gt;AutoML Vision Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Vision Object Detection
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Entity Extraction
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 10,000 characters, UTF-8 NFC encoded or a document in .PDF, .TIF or
   *       .TIFF format with size upto 20MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Sentiment Analysis
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Translation
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 25,000 characters, UTF-8 encoded.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Tables
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A row with column values matching the columns of the model, up to 5MB. Not available for
   *       FORECASTING `prediction_type`.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   ModelName name = ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;);
   *   ExamplePayload payload = ExamplePayload.newBuilder().build();
   *   Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
   *   PredictResponse response = predictionServiceClient.predict(name, payload, params);
   * }
   * }&lt;/pre&gt;
   *
   * @param name Required. Name of the model requested to serve the prediction.
   * @param payload Required. Payload to perform a prediction on. The payload must match the problem
   *     type that the model was trained to solve.
   * @param params Additional domain-specific parameters, any string must be up to 25000 characters
   *     long.
   *     &lt;p&gt;AutoML Vision Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for an image, it will only produce results that have at least this confidence score. The
   *     default is 0.5.
   *     &lt;p&gt;AutoML Vision Object Detection
   *     &lt;p&gt;`score_threshold` : (float) When Model detects objects on the image, it will only
   *     produce bounding boxes which have at least this confidence score. Value in 0 to 1 range,
   *     default is 0.5.
   *     &lt;p&gt;`max_bounding_box_count` : (int64) The maximum number of bounding boxes returned. The
   *     default is 100. The number of returned bounding boxes might be limited by the server.
   *     &lt;p&gt;AutoML Tables
   *     &lt;p&gt;`feature_importance` : (boolean) Whether
   *     [feature_importance][google.cloud.automl.v1.TablesModelColumnInfo.feature_importance] is
   *     populated in the returned list of
   *     [TablesAnnotation][google.cloud.automl.v1.TablesAnnotation] objects. The default is false.
   * @throws com.google.api.gax.rpc.ApiException if the remote call fails
   */
  public final PredictResponse predict(
      ModelName name, ExamplePayload payload, Map&lt;String, String&gt; params) {
    PredictRequest request =
<span class="fc" id="L256">        PredictRequest.newBuilder()</span>
<span class="pc bpc" id="L257" title="1 of 2 branches missed.">            .setName(name == null ? null : name.toString())</span>
<span class="fc" id="L258">            .setPayload(payload)</span>
<span class="fc" id="L259">            .putAllParams(params)</span>
<span class="fc" id="L260">            .build();</span>
<span class="fc" id="L261">    return predict(request);</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform an online prediction. The prediction result is directly returned in the response.
   * Available for following ML scenarios, and their expected request payloads:
   *
   * &lt;p&gt;AutoML Vision Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Vision Object Detection
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Entity Extraction
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 10,000 characters, UTF-8 NFC encoded or a document in .PDF, .TIF or
   *       .TIFF format with size upto 20MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Sentiment Analysis
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Translation
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 25,000 characters, UTF-8 encoded.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Tables
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A row with column values matching the columns of the model, up to 5MB. Not available for
   *       FORECASTING `prediction_type`.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   String name = ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString();
   *   ExamplePayload payload = ExamplePayload.newBuilder().build();
   *   Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
   *   PredictResponse response = predictionServiceClient.predict(name, payload, params);
   * }
   * }&lt;/pre&gt;
   *
   * @param name Required. Name of the model requested to serve the prediction.
   * @param payload Required. Payload to perform a prediction on. The payload must match the problem
   *     type that the model was trained to solve.
   * @param params Additional domain-specific parameters, any string must be up to 25000 characters
   *     long.
   *     &lt;p&gt;AutoML Vision Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for an image, it will only produce results that have at least this confidence score. The
   *     default is 0.5.
   *     &lt;p&gt;AutoML Vision Object Detection
   *     &lt;p&gt;`score_threshold` : (float) When Model detects objects on the image, it will only
   *     produce bounding boxes which have at least this confidence score. Value in 0 to 1 range,
   *     default is 0.5.
   *     &lt;p&gt;`max_bounding_box_count` : (int64) The maximum number of bounding boxes returned. The
   *     default is 100. The number of returned bounding boxes might be limited by the server.
   *     &lt;p&gt;AutoML Tables
   *     &lt;p&gt;`feature_importance` : (boolean) Whether
   *     [feature_importance][google.cloud.automl.v1.TablesModelColumnInfo.feature_importance] is
   *     populated in the returned list of
   *     [TablesAnnotation][google.cloud.automl.v1.TablesAnnotation] objects. The default is false.
   * @throws com.google.api.gax.rpc.ApiException if the remote call fails
   */
  public final PredictResponse predict(
      String name, ExamplePayload payload, Map&lt;String, String&gt; params) {
    PredictRequest request =
<span class="fc" id="L353">        PredictRequest.newBuilder().setName(name).setPayload(payload).putAllParams(params).build();</span>
<span class="fc" id="L354">    return predict(request);</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform an online prediction. The prediction result is directly returned in the response.
   * Available for following ML scenarios, and their expected request payloads:
   *
   * &lt;p&gt;AutoML Vision Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Vision Object Detection
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Entity Extraction
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 10,000 characters, UTF-8 NFC encoded or a document in .PDF, .TIF or
   *       .TIFF format with size upto 20MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Sentiment Analysis
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Translation
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 25,000 characters, UTF-8 encoded.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Tables
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A row with column values matching the columns of the model, up to 5MB. Not available for
   *       FORECASTING `prediction_type`.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   PredictRequest request =
   *       PredictRequest.newBuilder()
   *           .setName(ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString())
   *           .setPayload(ExamplePayload.newBuilder().build())
   *           .putAllParams(new HashMap&lt;String, String&gt;())
   *           .build();
   *   PredictResponse response = predictionServiceClient.predict(request);
   * }
   * }&lt;/pre&gt;
   *
   * @param request The request object containing all of the parameters for the API call.
   * @throws com.google.api.gax.rpc.ApiException if the remote call fails
   */
  public final PredictResponse predict(PredictRequest request) {
<span class="fc" id="L428">    return predictCallable().call(request);</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform an online prediction. The prediction result is directly returned in the response.
   * Available for following ML scenarios, and their expected request payloads:
   *
   * &lt;p&gt;AutoML Vision Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Vision Object Detection
   *
   * &lt;ul&gt;
   *   &lt;li&gt;An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Classification
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Entity Extraction
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 10,000 characters, UTF-8 NFC encoded or a document in .PDF, .TIF or
   *       .TIFF format with size upto 20MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Natural Language Sentiment Analysis
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in .PDF, .TIF or .TIFF
   *       format with size upto 2MB.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Translation
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A TextSnippet up to 25,000 characters, UTF-8 encoded.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;AutoML Tables
   *
   * &lt;ul&gt;
   *   &lt;li&gt;A row with column values matching the columns of the model, up to 5MB. Not available for
   *       FORECASTING `prediction_type`.
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   PredictRequest request =
   *       PredictRequest.newBuilder()
   *           .setName(ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString())
   *           .setPayload(ExamplePayload.newBuilder().build())
   *           .putAllParams(new HashMap&lt;String, String&gt;())
   *           .build();
   *   ApiFuture&lt;PredictResponse&gt; future =
   *       predictionServiceClient.predictCallable().futureCall(request);
   *   // Do something.
   *   PredictResponse response = future.get();
   * }
   * }&lt;/pre&gt;
   */
  public final UnaryCallable&lt;PredictRequest, PredictResponse&gt; predictCallable() {
<span class="fc" id="L502">    return stub.predictCallable();</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform a batch prediction. Unlike the online
   * [Predict][google.cloud.automl.v1.PredictionService.Predict], batch prediction result won't be
   * immediately available in the response. Instead, a long running operation object is returned.
   * User can poll the operation result via
   * [GetOperation][google.longrunning.Operations.GetOperation] method. Once the operation is done,
   * [BatchPredictResult][google.cloud.automl.v1.BatchPredictResult] is returned in the
   * [response][google.longrunning.Operation.response] field. Available for following ML scenarios:
   *
   * &lt;ul&gt;
   *   &lt;li&gt;AutoML Vision Classification
   *   &lt;li&gt;AutoML Vision Object Detection
   *   &lt;li&gt;AutoML Video Intelligence Classification
   *   &lt;li&gt;AutoML Video Intelligence Object Tracking &amp;#42; AutoML Natural Language Classification
   *   &lt;li&gt;AutoML Natural Language Entity Extraction
   *   &lt;li&gt;AutoML Natural Language Sentiment Analysis
   *   &lt;li&gt;AutoML Tables
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   ModelName name = ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;);
   *   BatchPredictInputConfig inputConfig = BatchPredictInputConfig.newBuilder().build();
   *   BatchPredictOutputConfig outputConfig = BatchPredictOutputConfig.newBuilder().build();
   *   Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
   *   BatchPredictResult response =
   *       predictionServiceClient.batchPredictAsync(name, inputConfig, outputConfig, params).get();
   * }
   * }&lt;/pre&gt;
   *
   * @param name Required. Name of the model requested to serve the batch prediction.
   * @param inputConfig Required. The input configuration for batch prediction.
   * @param outputConfig Required. The Configuration specifying where output predictions should be
   *     written.
   * @param params Additional domain-specific parameters for the predictions, any string must be up
   *     to 25000 characters long.
   *     &lt;p&gt;AutoML Natural Language Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for a text snippet, it will only produce results that have at least this confidence score.
   *     The default is 0.5.
   *     &lt;p&gt;AutoML Vision Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for an image, it will only produce results that have at least this confidence score. The
   *     default is 0.5.
   *     &lt;p&gt;AutoML Vision Object Detection
   *     &lt;p&gt;`score_threshold` : (float) When Model detects objects on the image, it will only
   *     produce bounding boxes which have at least this confidence score. Value in 0 to 1 range,
   *     default is 0.5.
   *     &lt;p&gt;`max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per
   *     image. The default is 100, the number of bounding boxes returned might be limited by the
   *     server. AutoML Video Intelligence Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for a video, it will only produce results that have at least this confidence score. The
   *     default is 0.5.
   *     &lt;p&gt;`segment_classification` : (boolean) Set to true to request segment-level
   *     classification. AutoML Video Intelligence returns labels and their confidence scores for
   *     the entire segment of the video that user specified in the request configuration. The
   *     default is true.
   *     &lt;p&gt;`shot_classification` : (boolean) Set to true to request shot-level classification.
   *     AutoML Video Intelligence determines the boundaries for each camera shot in the entire
   *     segment of the video that user specified in the request configuration. AutoML Video
   *     Intelligence then returns labels and their confidence scores for each detected shot, along
   *     with the start and end time of the shot. The default is false.
   *     &lt;p&gt;WARNING: Model evaluation is not done for this classification type, the quality of it
   *     depends on training data, but there are no metrics provided to describe that quality.
   *     &lt;p&gt;`1s_interval_classification` : (boolean) Set to true to request classification for a
   *     video at one-second intervals. AutoML Video Intelligence returns labels and their
   *     confidence scores for each second of the entire segment of the video that user specified in
   *     the request configuration. The default is false.
   *     &lt;p&gt;WARNING: Model evaluation is not done for this classification type, the quality of it
   *     depends on training data, but there are no metrics provided to describe that quality.
   *     &lt;p&gt;AutoML Video Intelligence Object Tracking
   *     &lt;p&gt;`score_threshold` : (float) When Model detects objects on video frames, it will only
   *     produce bounding boxes which have at least this confidence score. Value in 0 to 1 range,
   *     default is 0.5.
   *     &lt;p&gt;`max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per
   *     image. The default is 100, the number of bounding boxes returned might be limited by the
   *     server.
   *     &lt;p&gt;`min_bounding_box_size` : (float) Only bounding boxes with shortest edge at least that
   *     long as a relative value of video frame size are returned. Value in 0 to 1 range. Default
   *     is 0.
   * @throws com.google.api.gax.rpc.ApiException if the remote call fails
   */
  public final OperationFuture&lt;BatchPredictResult, OperationMetadata&gt; batchPredictAsync(
      ModelName name,
      BatchPredictInputConfig inputConfig,
      BatchPredictOutputConfig outputConfig,
      Map&lt;String, String&gt; params) {
    BatchPredictRequest request =
<span class="fc" id="L599">        BatchPredictRequest.newBuilder()</span>
<span class="pc bpc" id="L600" title="1 of 2 branches missed.">            .setName(name == null ? null : name.toString())</span>
<span class="fc" id="L601">            .setInputConfig(inputConfig)</span>
<span class="fc" id="L602">            .setOutputConfig(outputConfig)</span>
<span class="fc" id="L603">            .putAllParams(params)</span>
<span class="fc" id="L604">            .build();</span>
<span class="fc" id="L605">    return batchPredictAsync(request);</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform a batch prediction. Unlike the online
   * [Predict][google.cloud.automl.v1.PredictionService.Predict], batch prediction result won't be
   * immediately available in the response. Instead, a long running operation object is returned.
   * User can poll the operation result via
   * [GetOperation][google.longrunning.Operations.GetOperation] method. Once the operation is done,
   * [BatchPredictResult][google.cloud.automl.v1.BatchPredictResult] is returned in the
   * [response][google.longrunning.Operation.response] field. Available for following ML scenarios:
   *
   * &lt;ul&gt;
   *   &lt;li&gt;AutoML Vision Classification
   *   &lt;li&gt;AutoML Vision Object Detection
   *   &lt;li&gt;AutoML Video Intelligence Classification
   *   &lt;li&gt;AutoML Video Intelligence Object Tracking &amp;#42; AutoML Natural Language Classification
   *   &lt;li&gt;AutoML Natural Language Entity Extraction
   *   &lt;li&gt;AutoML Natural Language Sentiment Analysis
   *   &lt;li&gt;AutoML Tables
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   String name = ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString();
   *   BatchPredictInputConfig inputConfig = BatchPredictInputConfig.newBuilder().build();
   *   BatchPredictOutputConfig outputConfig = BatchPredictOutputConfig.newBuilder().build();
   *   Map&lt;String, String&gt; params = new HashMap&lt;&gt;();
   *   BatchPredictResult response =
   *       predictionServiceClient.batchPredictAsync(name, inputConfig, outputConfig, params).get();
   * }
   * }&lt;/pre&gt;
   *
   * @param name Required. Name of the model requested to serve the batch prediction.
   * @param inputConfig Required. The input configuration for batch prediction.
   * @param outputConfig Required. The Configuration specifying where output predictions should be
   *     written.
   * @param params Additional domain-specific parameters for the predictions, any string must be up
   *     to 25000 characters long.
   *     &lt;p&gt;AutoML Natural Language Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for a text snippet, it will only produce results that have at least this confidence score.
   *     The default is 0.5.
   *     &lt;p&gt;AutoML Vision Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for an image, it will only produce results that have at least this confidence score. The
   *     default is 0.5.
   *     &lt;p&gt;AutoML Vision Object Detection
   *     &lt;p&gt;`score_threshold` : (float) When Model detects objects on the image, it will only
   *     produce bounding boxes which have at least this confidence score. Value in 0 to 1 range,
   *     default is 0.5.
   *     &lt;p&gt;`max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per
   *     image. The default is 100, the number of bounding boxes returned might be limited by the
   *     server. AutoML Video Intelligence Classification
   *     &lt;p&gt;`score_threshold` : (float) A value from 0.0 to 1.0. When the model makes predictions
   *     for a video, it will only produce results that have at least this confidence score. The
   *     default is 0.5.
   *     &lt;p&gt;`segment_classification` : (boolean) Set to true to request segment-level
   *     classification. AutoML Video Intelligence returns labels and their confidence scores for
   *     the entire segment of the video that user specified in the request configuration. The
   *     default is true.
   *     &lt;p&gt;`shot_classification` : (boolean) Set to true to request shot-level classification.
   *     AutoML Video Intelligence determines the boundaries for each camera shot in the entire
   *     segment of the video that user specified in the request configuration. AutoML Video
   *     Intelligence then returns labels and their confidence scores for each detected shot, along
   *     with the start and end time of the shot. The default is false.
   *     &lt;p&gt;WARNING: Model evaluation is not done for this classification type, the quality of it
   *     depends on training data, but there are no metrics provided to describe that quality.
   *     &lt;p&gt;`1s_interval_classification` : (boolean) Set to true to request classification for a
   *     video at one-second intervals. AutoML Video Intelligence returns labels and their
   *     confidence scores for each second of the entire segment of the video that user specified in
   *     the request configuration. The default is false.
   *     &lt;p&gt;WARNING: Model evaluation is not done for this classification type, the quality of it
   *     depends on training data, but there are no metrics provided to describe that quality.
   *     &lt;p&gt;AutoML Video Intelligence Object Tracking
   *     &lt;p&gt;`score_threshold` : (float) When Model detects objects on video frames, it will only
   *     produce bounding boxes which have at least this confidence score. Value in 0 to 1 range,
   *     default is 0.5.
   *     &lt;p&gt;`max_bounding_box_count` : (int64) The maximum number of bounding boxes returned per
   *     image. The default is 100, the number of bounding boxes returned might be limited by the
   *     server.
   *     &lt;p&gt;`min_bounding_box_size` : (float) Only bounding boxes with shortest edge at least that
   *     long as a relative value of video frame size are returned. Value in 0 to 1 range. Default
   *     is 0.
   * @throws com.google.api.gax.rpc.ApiException if the remote call fails
   */
  public final OperationFuture&lt;BatchPredictResult, OperationMetadata&gt; batchPredictAsync(
      String name,
      BatchPredictInputConfig inputConfig,
      BatchPredictOutputConfig outputConfig,
      Map&lt;String, String&gt; params) {
    BatchPredictRequest request =
<span class="fc" id="L702">        BatchPredictRequest.newBuilder()</span>
<span class="fc" id="L703">            .setName(name)</span>
<span class="fc" id="L704">            .setInputConfig(inputConfig)</span>
<span class="fc" id="L705">            .setOutputConfig(outputConfig)</span>
<span class="fc" id="L706">            .putAllParams(params)</span>
<span class="fc" id="L707">            .build();</span>
<span class="fc" id="L708">    return batchPredictAsync(request);</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform a batch prediction. Unlike the online
   * [Predict][google.cloud.automl.v1.PredictionService.Predict], batch prediction result won't be
   * immediately available in the response. Instead, a long running operation object is returned.
   * User can poll the operation result via
   * [GetOperation][google.longrunning.Operations.GetOperation] method. Once the operation is done,
   * [BatchPredictResult][google.cloud.automl.v1.BatchPredictResult] is returned in the
   * [response][google.longrunning.Operation.response] field. Available for following ML scenarios:
   *
   * &lt;ul&gt;
   *   &lt;li&gt;AutoML Vision Classification
   *   &lt;li&gt;AutoML Vision Object Detection
   *   &lt;li&gt;AutoML Video Intelligence Classification
   *   &lt;li&gt;AutoML Video Intelligence Object Tracking &amp;#42; AutoML Natural Language Classification
   *   &lt;li&gt;AutoML Natural Language Entity Extraction
   *   &lt;li&gt;AutoML Natural Language Sentiment Analysis
   *   &lt;li&gt;AutoML Tables
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   BatchPredictRequest request =
   *       BatchPredictRequest.newBuilder()
   *           .setName(ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString())
   *           .setInputConfig(BatchPredictInputConfig.newBuilder().build())
   *           .setOutputConfig(BatchPredictOutputConfig.newBuilder().build())
   *           .putAllParams(new HashMap&lt;String, String&gt;())
   *           .build();
   *   BatchPredictResult response = predictionServiceClient.batchPredictAsync(request).get();
   * }
   * }&lt;/pre&gt;
   *
   * @param request The request object containing all of the parameters for the API call.
   * @throws com.google.api.gax.rpc.ApiException if the remote call fails
   */
  public final OperationFuture&lt;BatchPredictResult, OperationMetadata&gt; batchPredictAsync(
      BatchPredictRequest request) {
<span class="fc" id="L753">    return batchPredictOperationCallable().futureCall(request);</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform a batch prediction. Unlike the online
   * [Predict][google.cloud.automl.v1.PredictionService.Predict], batch prediction result won't be
   * immediately available in the response. Instead, a long running operation object is returned.
   * User can poll the operation result via
   * [GetOperation][google.longrunning.Operations.GetOperation] method. Once the operation is done,
   * [BatchPredictResult][google.cloud.automl.v1.BatchPredictResult] is returned in the
   * [response][google.longrunning.Operation.response] field. Available for following ML scenarios:
   *
   * &lt;ul&gt;
   *   &lt;li&gt;AutoML Vision Classification
   *   &lt;li&gt;AutoML Vision Object Detection
   *   &lt;li&gt;AutoML Video Intelligence Classification
   *   &lt;li&gt;AutoML Video Intelligence Object Tracking &amp;#42; AutoML Natural Language Classification
   *   &lt;li&gt;AutoML Natural Language Entity Extraction
   *   &lt;li&gt;AutoML Natural Language Sentiment Analysis
   *   &lt;li&gt;AutoML Tables
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   BatchPredictRequest request =
   *       BatchPredictRequest.newBuilder()
   *           .setName(ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString())
   *           .setInputConfig(BatchPredictInputConfig.newBuilder().build())
   *           .setOutputConfig(BatchPredictOutputConfig.newBuilder().build())
   *           .putAllParams(new HashMap&lt;String, String&gt;())
   *           .build();
   *   OperationFuture&lt;BatchPredictResult, OperationMetadata&gt; future =
   *       predictionServiceClient.batchPredictOperationCallable().futureCall(request);
   *   // Do something.
   *   BatchPredictResult response = future.get();
   * }
   * }&lt;/pre&gt;
   */
  public final OperationCallable&lt;BatchPredictRequest, BatchPredictResult, OperationMetadata&gt;
      batchPredictOperationCallable() {
<span class="fc" id="L798">    return stub.batchPredictOperationCallable();</span>
  }

  // AUTO-GENERATED DOCUMENTATION AND METHOD.
  /**
   * Perform a batch prediction. Unlike the online
   * [Predict][google.cloud.automl.v1.PredictionService.Predict], batch prediction result won't be
   * immediately available in the response. Instead, a long running operation object is returned.
   * User can poll the operation result via
   * [GetOperation][google.longrunning.Operations.GetOperation] method. Once the operation is done,
   * [BatchPredictResult][google.cloud.automl.v1.BatchPredictResult] is returned in the
   * [response][google.longrunning.Operation.response] field. Available for following ML scenarios:
   *
   * &lt;ul&gt;
   *   &lt;li&gt;AutoML Vision Classification
   *   &lt;li&gt;AutoML Vision Object Detection
   *   &lt;li&gt;AutoML Video Intelligence Classification
   *   &lt;li&gt;AutoML Video Intelligence Object Tracking &amp;#42; AutoML Natural Language Classification
   *   &lt;li&gt;AutoML Natural Language Entity Extraction
   *   &lt;li&gt;AutoML Natural Language Sentiment Analysis
   *   &lt;li&gt;AutoML Tables
   * &lt;/ul&gt;
   *
   * &lt;p&gt;Sample code:
   *
   * &lt;pre&gt;{@code
   * // This snippet has been automatically generated for illustrative purposes only.
   * // It may require modifications to work in your environment.
   * try (PredictionServiceClient predictionServiceClient = PredictionServiceClient.create()) {
   *   BatchPredictRequest request =
   *       BatchPredictRequest.newBuilder()
   *           .setName(ModelName.of(&quot;[PROJECT]&quot;, &quot;[LOCATION]&quot;, &quot;[MODEL]&quot;).toString())
   *           .setInputConfig(BatchPredictInputConfig.newBuilder().build())
   *           .setOutputConfig(BatchPredictOutputConfig.newBuilder().build())
   *           .putAllParams(new HashMap&lt;String, String&gt;())
   *           .build();
   *   ApiFuture&lt;Operation&gt; future =
   *       predictionServiceClient.batchPredictCallable().futureCall(request);
   *   // Do something.
   *   Operation response = future.get();
   * }
   * }&lt;/pre&gt;
   */
  public final UnaryCallable&lt;BatchPredictRequest, Operation&gt; batchPredictCallable() {
<span class="nc" id="L842">    return stub.batchPredictCallable();</span>
  }

  @Override
  public final void close() {
<span class="fc" id="L847">    stub.close();</span>
<span class="fc" id="L848">  }</span>

  @Override
  public void shutdown() {
<span class="nc" id="L852">    stub.shutdown();</span>
<span class="nc" id="L853">  }</span>

  @Override
  public boolean isShutdown() {
<span class="nc" id="L857">    return stub.isShutdown();</span>
  }

  @Override
  public boolean isTerminated() {
<span class="nc" id="L862">    return stub.isTerminated();</span>
  }

  @Override
  public void shutdownNow() {
<span class="nc" id="L867">    stub.shutdownNow();</span>
<span class="nc" id="L868">  }</span>

  @Override
  public boolean awaitTermination(long duration, TimeUnit unit) throws InterruptedException {
<span class="nc" id="L872">    return stub.awaitTermination(duration, unit);</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>